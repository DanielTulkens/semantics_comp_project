{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | N | PropN | Adj NP | NP PP\n",
    "    VP -> V | Vbar NP | Vbar NP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> V\n",
    "    AdvP -> Adv P\n",
    "    PP -> P NP\n",
    "    Det -> 'a' | 'an' | 'the' | 'every'| 'some' | 'any'\n",
    "    P -> 'with' | 'in' | 'on' | 'to' | 'without' | 'from'\n",
    "    Conj -> 'and' | 'or' | 'but'\n",
    "\n",
    "\n",
    "    N -> 'boy' | 'student' | 'girl' | 'class' | 'book' | 'teacher'\n",
    "    PropN -> 'john' | 'mary'\n",
    "    Adj -> 'eager' | 'smart'\n",
    "    V -> 'walks' | 'passed' | 'sees' | 'studies' | 'teaches' | 'saw' \n",
    "    Adv -> 'eagerly' | 'well'\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ 'John sees Mary', 'A student walks', 'Some girl sees every boy','Every eager student passed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = random.choice(sentences)\n",
    "parser = nltk.parse.RecursiveDescentParser(grammar)                            \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    print(parse_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()\n",
    "\n",
    "#select the verb for the sentence 'john sees mary' \n",
    "print(parse_tree[1,0])\n",
    "#select the subject for the sentence 'john sees mary'\n",
    "print(parse_tree[0])\n",
    "#select the determiner for sentence 'A student walks'\n",
    "sentence = sentences[1]\n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()\n",
    "print(parse_tree[0,0])\n",
    "print('\\n' )\n",
    "\n",
    "#practice iterating\n",
    "for subtree in parse_tree.subtrees(): \n",
    "    print(subtree)\n",
    "print('\\n' )\n",
    "for pos in parse_tree.treepositions(): \n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"leaves\"):\n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"postorder\"):\n",
    "  print(pos)\n",
    "print('\\n')\n",
    "\n",
    "#get parent node \n",
    "\n",
    "def get_parent_node(child_tuple): \n",
    "    if len(child_tuple) >= 1: \n",
    "        parent_node = child_tuple[:-1]\n",
    "        return parent_node\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#get verb tuple \n",
    "def get_verb_tuple(tree):\n",
    "    for node in tree.treepositions(order=\"leaves\"):\n",
    "        if tree[get_parent_node(node)].label() in [\"Vi\", \"Vt\"]:\n",
    "            return node\n",
    "\n",
    "verb = get_verb_tuple(parse_tree) #calling the get verb \n",
    "print(parse_tree.pretty_print())\n",
    "print(verb)\n",
    "\n",
    "\n",
    "\n",
    "# #Define a function that takes a parse tree, and returns the position of the subject DP.\n",
    "def get_subj_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] != VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "dp = get_subj_pos(parse_tree)\n",
    "print(dp)\n",
    "\n",
    "\n",
    "#Define a function that takes a parse tree, and returns the position of the object DP if one exists, and None otherwise\n",
    "def get_object_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] == VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "obj = get_object_pos(parse_tree)\n",
    "print(obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = { \n",
    "    'John sees Mary' : 'SEES(j,m)', \n",
    "    'A student walks': 'some x [WALK(x)]', \n",
    "    'Some girl sees every boy': 'all y some x [(GIRL(x) ∧ BOY(y)) → SEES(x, y))]',\n",
    "    'Every eager student passed':' ' }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {\n",
    "    'P': (\n",
    "        'with',\n",
    "        'in',\n",
    "        'on',\n",
    "        'to',\n",
    "        'without',\n",
    "        'from'\n",
    "    ),\n",
    "    'N': (\n",
    "        'boy',\n",
    "        'student',\n",
    "        'girl',\n",
    "        'class',\n",
    "        'book',\n",
    "        'teacher'\n",
    "    ),\n",
    "    'PropN': (\n",
    "        'john',\n",
    "        'mary'\n",
    "    ),\n",
    "    'Vi': (\n",
    "        'walks',\n",
    "        'passed'\n",
    "    ),\n",
    "    'Vt': (\n",
    "        'sees',\n",
    "        'teaches'\n",
    "    ),\n",
    "    'Adj': (\n",
    "        'eager',\n",
    "        'smart'\n",
    "    ),\n",
    "    'Adv': (\n",
    "        'eagerly',\n",
    "        'well'\n",
    "    ),\n",
    "    'Det': (\n",
    "        'a',\n",
    "        'an',\n",
    "        'the',\n",
    "        'every',\n",
    "        'some',\n",
    "        'any'\n",
    "    ),\n",
    "    'Conj': (\n",
    "        'and',\n",
    "        'or',\n",
    "        'but'\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class would create an object storing both the representation of an element, and its typing information\n",
    "class Formalization:\n",
    "    def _init_(self, formula, type_hint):\n",
    "        self.formula = formula\n",
    "        self.type = type_hint\n",
    "        if type(type_hint) == tuple:\n",
    "            self.selected = type_hint[0]\n",
    "            self.returned = type_hint[1]\n",
    "        else:\n",
    "            self.selected = None\n",
    "\n",
    "    def application(self, argument):\n",
    "        if argument.type == self.selected:\n",
    "            resulting_formula = self.formula(argument.formula)\n",
    "            return Formalization(resulting_formula, self.returned)\n",
    "\n",
    "\n",
    "# this dictionary contains functions to generate lexical entries for different parts of speech.\n",
    "formalizations = {\n",
    "    'PropN': lambda name: Formalization(\n",
    "        name,\n",
    "        'e'\n",
    "    ),\n",
    "    'N': lambda noun: Formalization(\n",
    "        lambda x: f'{noun.upper()}({x})',\n",
    "        ('e', 't')\n",
    "    ),\n",
    "    'Vi': lambda verb: Formalization(\n",
    "        lambda x: f'{verb.upper()}({x})',\n",
    "        ('e', 't')\n",
    "    ),\n",
    "    'Vt': lambda verb: Formalization(\n",
    "        lambda y: lambda x: f'{verb.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't'))\n",
    "    ),\n",
    "    'Adj': lambda adjective: Formalization(\n",
    "        lambda P: lambda x: f'{adjective.upper()}({x}) ^ {P(x)}',\n",
    "        (('e', 't'), ('e', 't'))\n",
    "    ),\n",
    "    'Adv': lambda adverb: Formalization(\n",
    "        lambda P: lambda x: f'{adverb.upper()}({P(x)})',\n",
    "        (('e', 't'), ('e', 't'))\n",
    "    ),\n",
    "    'P': lambda preposition: Formalization(\n",
    "        lambda x: lambda y: f'{preposition.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't'))\n",
    "    ),\n",
    "    'existential': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'Exists x[{P(\"x\")} ^ {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't'))\n",
    "    ),\n",
    "    'universal': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'All x[{P(\"x\")} -> {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't'))\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def generate_lexicon(vocab, translations):\n",
    "    lexicon = {}\n",
    "    for part_of_speech, entries in vocab.items():\n",
    "        if part_of_speech in translations.keys():\n",
    "            lexicon.update({part_of_speech: {word: translations[part_of_speech](word) for word in entries}})\n",
    "        elif type(entries) == dict:\n",
    "            lexicon[part_of_speech] = {}\n",
    "            for subtype, words in entries.items():\n",
    "                lexicon[part_of_speech].update({word: translations[subtype](word) for word in words})\n",
    "        else:\n",
    "            lexicon.update({part_of_speech: {word: Formalization(word, 'e') for word in entries}})\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def lexicon_to_terminals(lexicon):\n",
    "    terminal_rules = ''\n",
    "    for part_of_speech in lexicon.keys():\n",
    "        terminals_string = \" | \".join([\"'\" + word + \"'\" for word in lexicon[part_of_speech].keys()])\n",
    "        terminal_rules += (part_of_speech + ' -> ' + terminals_string + '\\n\\t')\n",
    "    return terminal_rules\n",
    "\n",
    "\n",
    "extensional_lexicon = generate_lexicon(vocabulary, formalizations)\n",
    "\n",
    "terminals_entries = lexicon_to_terminals(extensional_lexicon)\n",
    "\n",
    "extensional_grammar = f\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det Nom | PropN\n",
    "    Nom -> N  | Adj Nom | Nom PP\n",
    "    VP -> Vi | Vt  | Vbar NP | Vbar NP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P NP\n",
    "    \n",
    "    {terminals_entries}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_logic(tree = nltk.Tree, pos=None):\n",
    "    if  ['every','some','any'] in tree.leaves():\n",
    "        return None \n",
    "    else: \n",
    "    \n",
    "    \n",
    "    v = tree[pos[0]]\n",
    "    print(len(v))\n",
    "    print(pos)\n",
    "    print(tree[pos[0]])\n",
    "    if type(v) == nltk.Tree:\n",
    "        print(v.label())\n",
    "        if v.label() == 'S' and len(v) == 2:\n",
    "            return translate_to_logic(tree, pos[1:])(translate_to_logic(tree, pos[2:]))\n",
    "        else:\n",
    "            return translate_to_logic(tree,pos[1:])\n",
    "    else:\n",
    "        return formalizations[tree[pos[0][:-1]].label()](tree[pos[0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "translate_to_logic(parse_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
