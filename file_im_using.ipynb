{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "import sys \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> DP VP\n",
    "    DP -> Det NP | NP | DP Conj DP\n",
    "    NP -> N | PropN | Adj NP | NP PP\n",
    "    VP -> Vi | Vt  | Vbar DP | Vbar DP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P DP\n",
    "    Det -> 'a' | 'an' | 'the' | 'every'| 'some' | 'any'\n",
    "    P -> 'with' | 'in' | 'on' | 'to' | 'without' | 'from'\n",
    "    Conj -> 'and' | 'or' | 'but'\n",
    "\n",
    "\n",
    "    N -> 'boy' | 'student' | 'girl' | 'class' | 'book' | 'teacher'\n",
    "    PropN -> 'john' | 'mary'\n",
    "    Adj -> 'eager' | 'smart'\n",
    "    Vi -> 'walks' | 'passed' \n",
    "    Vt -> 'sees' | 'teaches'\n",
    "    Adv -> 'eagerly' | 'well'\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ 'John sees Mary', 'A student walks', 'Some girl sees every boy','Every eager student passed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (DP (NP (PropN john)))\n",
      "  (VP (Vbar (Vt sees)) (DP (NP (PropN mary)))))\n"
     ]
    }
   ],
   "source": [
    "# sentence = random.choice(sentences)\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    print(parse_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S            \n",
      "   ____|____         \n",
      "  |         VP      \n",
      "  |     ____|____    \n",
      "  DP   |         DP \n",
      "  |    |         |   \n",
      "  NP  Vbar       NP \n",
      "  |    |         |   \n",
      "PropN  Vt      PropN\n",
      "  |    |         |   \n",
      " john sees      mary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Vbar (Vt sees))\n",
      "(DP (NP (PropN john)))\n",
      "           S         \n",
      "      _____|______    \n",
      "     DP           |  \n",
      "  ___|_____       |   \n",
      " |         NP     VP \n",
      " |         |      |   \n",
      "Det        N      Vi \n",
      " |         |      |   \n",
      " a      student walks\n",
      "\n",
      "(Det a)\n",
      "\n",
      "\n",
      "(S (DP (Det a) (NP (N student))) (VP (Vi walks)))\n",
      "(DP (Det a) (NP (N student)))\n",
      "(Det a)\n",
      "(NP (N student))\n",
      "(N student)\n",
      "(VP (Vi walks))\n",
      "(Vi walks)\n",
      "\n",
      "\n",
      "()\n",
      "(0,)\n",
      "(0, 0)\n",
      "(0, 0, 0)\n",
      "(0, 1)\n",
      "(0, 1, 0)\n",
      "(0, 1, 0, 0)\n",
      "(1,)\n",
      "(1, 0)\n",
      "(1, 0, 0)\n",
      "\n",
      "\n",
      "(0, 0, 0)\n",
      "(0, 1, 0, 0)\n",
      "(1, 0, 0)\n",
      "\n",
      "\n",
      "(0, 0, 0)\n",
      "(0, 0)\n",
      "(0, 1, 0, 0)\n",
      "(0, 1, 0)\n",
      "(0, 1)\n",
      "(0,)\n",
      "(1, 0, 0)\n",
      "(1, 0)\n",
      "(1,)\n",
      "()\n",
      "\n",
      "\n",
      "           S         \n",
      "      _____|______    \n",
      "     DP           |  \n",
      "  ___|_____       |   \n",
      " |         NP     VP \n",
      " |         |      |   \n",
      "Det        N      Vi \n",
      " |         |      |   \n",
      " a      student walks\n",
      "\n",
      "None\n",
      "(1, 0, 0)\n",
      "(0,)\n",
      "       S            \n",
      "   ____|____         \n",
      "  |         VP      \n",
      "  |     ____|____    \n",
      "  DP   |         DP \n",
      "  |    |         |   \n",
      "  NP  Vbar       NP \n",
      "  |    |         |   \n",
      "PropN  Vt      PropN\n",
      "  |    |         |   \n",
      " john sees      mary\n",
      "\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "#select the verb for the sentence 'john sees mary' \n",
    "print(parse_tree[1,0])\n",
    "#select the subject for the sentence 'john sees mary'\n",
    "print(parse_tree[0])\n",
    "#select the determiner for sentence 'A student walks'\n",
    "sentence = sentences[1]\n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()\n",
    "print(parse_tree[0,0])\n",
    "print('\\n' )\n",
    "\n",
    "#practice iterating\n",
    "for subtree in parse_tree.subtrees(): \n",
    "    print(subtree)\n",
    "print('\\n' )\n",
    "for pos in parse_tree.treepositions(): \n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"leaves\"):\n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"postorder\"):\n",
    "  print(pos)\n",
    "print('\\n')\n",
    "\n",
    "#get parent node \n",
    "\n",
    "def get_parent_node(child_tuple): \n",
    "    if len(child_tuple) >= 1: \n",
    "        parent_node = child_tuple[:-1]\n",
    "        return parent_node\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#get verb tuple \n",
    "def get_verb_tuple(tree):\n",
    "    for node in tree.treepositions(order=\"leaves\"):\n",
    "        if tree[get_parent_node(node)].label() in [\"Vi\", \"Vt\"]:\n",
    "            return node\n",
    "\n",
    "verb = get_verb_tuple(parse_tree) #calling the get verb \n",
    "print(parse_tree.pretty_print())\n",
    "print(verb)\n",
    "\n",
    "\n",
    "\n",
    "# #Define a function that takes a parse tree, and returns the position of the subject DP.\n",
    "def get_subj_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] != VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "dp = get_subj_pos(parse_tree)\n",
    "print(dp)\n",
    "\n",
    "\n",
    "#Define a function that takes a parse tree, and returns the position of the object DP if one exists, and None otherwise\n",
    "def get_object_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] == VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "obj = get_object_pos(parse_tree)\n",
    "print(obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = { \n",
    "    'John sees Mary' : 'SEES(j,m)', \n",
    "    'A student walks': 'some x [WALK(x)]', \n",
    "    'Some girl sees every boy': 'all y some x [(GIRL(x) ∧ BOY(y)) → SEES(x, y))]',\n",
    "    'Every eager student passed': ''}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {\n",
    "    'P': (\n",
    "        'with',\n",
    "        'in',\n",
    "        'on',\n",
    "        'to',\n",
    "        'without',\n",
    "        'from'\n",
    "    ),\n",
    "    'N': (\n",
    "        'boy',\n",
    "        'student',\n",
    "        'girl',\n",
    "        'class',\n",
    "        'book',\n",
    "        'teacher'\n",
    "    ),\n",
    "    'PropN': (\n",
    "        'john',\n",
    "        'mary'\n",
    "    ),\n",
    "    'Vi': (\n",
    "        'walks',\n",
    "        'passed'\n",
    "    ),\n",
    "    'Vt': (\n",
    "        'sees',\n",
    "        'teaches'\n",
    "    ),\n",
    "    'Adj': (\n",
    "        'eager',\n",
    "        'smart'\n",
    "    ),\n",
    "    'Adv': (\n",
    "        'eagerly',\n",
    "        'well'\n",
    "    ),\n",
    "    'Det': (\n",
    "        'a',\n",
    "        'an',\n",
    "        'the',\n",
    "        'every',\n",
    "        'some',\n",
    "        'any'\n",
    "    ),\n",
    "    'Conj': (\n",
    "        'and',\n",
    "        'or',\n",
    "        'but'\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class would create an object storing both the representation of an element, and its typing information\n",
    "class Formalization:\n",
    "    def __init__(self, formula, type_hint, type_=None):\n",
    "        self.formula = formula\n",
    "        self.type = type_hint\n",
    "        self.t = type_\n",
    "        if type(type_hint) == tuple:\n",
    "            self.selected = type_hint[0]\n",
    "            self.returned = type_hint[1]\n",
    "        else:\n",
    "            self.selected = None\n",
    "\n",
    "    def application(self, argument):\n",
    "        if argument.type == self.selected:\n",
    "            resulting_formula = self.formula(argument.formula)\n",
    "            return Formalization(resulting_formula, self.returned)\n",
    "\n",
    "\n",
    "# this dictionary contains functions to generate lexical entries for different parts of speech.\n",
    "formalizations = {\n",
    "    'PropN': lambda name: Formalization(\n",
    "        name,\n",
    "        'e', 'PropN'\n",
    "    ),\n",
    "    'N': lambda noun: Formalization(\n",
    "        lambda x: f'{noun.upper()}({x})',\n",
    "        ('e', 't'), 'N'\n",
    "    ),\n",
    "    'Vi': lambda verb: Formalization(\n",
    "        lambda x: f'{verb.upper()}({x})',\n",
    "        ('e', 't'), 'Vi'\n",
    "    ),\n",
    "    'Vt': lambda verb: Formalization(\n",
    "        lambda y: lambda x: f'{verb.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't')), 'Vt'\n",
    "    ),\n",
    "    'Adj': lambda adjective: Formalization(\n",
    "        lambda P: lambda x: f'{adjective.upper()}({x}) ^ {P(x)}',\n",
    "        (('e', 't'), ('e', 't')), 'Adj'\n",
    "    ),\n",
    "    'Adv': lambda adverb: Formalization(\n",
    "        lambda P: lambda x: f'{adverb.upper()}({P(x)})',\n",
    "        (('e', 't'), ('e', 't')), 'Adv'\n",
    "    ),\n",
    "    'P': lambda preposition: Formalization(\n",
    "        lambda x: lambda y: f'{preposition.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't')), 'P'\n",
    "    ),\n",
    "    'existential': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'Exists x[{P(\"x\")} ^ {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't')), 'existential'\n",
    "    ),\n",
    "    'universal': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'All x[{P(\"x\")} -> {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't')), 'universal'\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def generate_lexicon(vocab, translations):\n",
    "    lexicon = {}\n",
    "    for part_of_speech, entries in vocab.items():\n",
    "        if part_of_speech in translations.keys():\n",
    "            lexicon.update({part_of_speech: {word: translations[part_of_speech](word) for word in entries}})\n",
    "        elif type(entries) == dict:\n",
    "            lexicon[part_of_speech] = {}\n",
    "            for subtype, words in entries.items():\n",
    "                lexicon[part_of_speech].update({word: translations[subtype](word) for word in words})\n",
    "        else:\n",
    "            lexicon.update({part_of_speech: {word: Formalization(word, 'e') for word in entries}})\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def lexicon_to_terminals(lexicon):\n",
    "    terminal_rules = ''\n",
    "    for part_of_speech in lexicon.keys():\n",
    "        terminals_string = \" | \".join([\"'\" + word + \"'\" for word in lexicon[part_of_speech].keys()])\n",
    "        terminal_rules += (part_of_speech + ' -> ' + terminals_string + '\\n\\t')\n",
    "    return terminal_rules\n",
    "\n",
    "\n",
    "extensional_lexicon = generate_lexicon(vocabulary, formalizations)\n",
    "\n",
    "terminals_entries = lexicon_to_terminals(extensional_lexicon)\n",
    "\n",
    "extensional_grammar = f\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det Nom | PropN\n",
    "    Nom -> N  | Adj Nom | Nom PP\n",
    "    VP -> Vi | Vt  | Vbar NP | Vbar NP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P NP\n",
    "    {terminals_entries}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S            \n",
      "   ____|____         \n",
      "  |         VP      \n",
      "  |     ____|____    \n",
      "  DP   |         DP \n",
      "  |    |         |   \n",
      "  NP  Vbar       NP \n",
      "  |    |         |   \n",
      "PropN  Vt      PropN\n",
      "  |    |         |   \n",
      " john sees      mary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SEES(john, mary)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existentials = ['a', 'some', 'an']\n",
    "universal = ['every']\n",
    "def translate_to_logic(tree = nltk.Tree):\n",
    "    result = {}\n",
    "    prev_was_leave = False\n",
    "    leaf = ''\n",
    "    root_cause = None\n",
    "    for node in tree.treepositions(order='postorder'):\n",
    "        if isinstance(tree[node], nltk.Tree):\n",
    "            if len(tree[node]) > 1:\n",
    "                if tree[node].label() == 'S':\n",
    "                    if result[node + (1,)].t == 'existential':\n",
    "                        result[node] = result[node + (0,)].application(result[node + (1,)])\n",
    "                    else:\n",
    "                        result[node] = result[node + (1,)].application(result[node + (0,)])\n",
    "                else:\n",
    "                    result[node] = result[node + (0,)].application(result[node + (1,)])\n",
    "            else:\n",
    "                if prev_was_leave:\n",
    "                    if leaf in existentials:\n",
    "                        applier = 'existential'\n",
    "                    elif leaf in universal:\n",
    "                        applier = 'universal'\n",
    "                    else:\n",
    "                        applier = tree[node].label()\n",
    "                    result[node] = formalizations[applier](leaf)\n",
    "                    root_cause = result[node]\n",
    "                    prev_was_leave = False\n",
    "                else:\n",
    "                    result[node] = root_cause\n",
    "        else:\n",
    "            prev_was_leave = True\n",
    "            leaf = tree[node]\n",
    "    return result\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "res = translate_to_logic(parse_tree)\n",
    "res[()].formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PropN': <function __main__.<lambda>(name)>,\n",
       " 'N': <function __main__.<lambda>(noun)>,\n",
       " 'Vi': <function __main__.<lambda>(verb)>,\n",
       " 'Vt': <function __main__.<lambda>(verb)>,\n",
       " 'Adj': <function __main__.<lambda>(adjective)>,\n",
       " 'Adv': <function __main__.<lambda>(adverb)>,\n",
       " 'P': <function __main__.<lambda>(preposition)>,\n",
       " 'existential': <function __main__.<lambda>(_)>,\n",
       " 'universal': <function __main__.<lambda>(_)>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Formalization' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/12/g9jxbl9x6wgd_gz_t2l352pc0000gn/T/ipykernel_31746/2317420166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mformalizations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'walk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'john'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Formalization' object is not callable"
     ]
    }
   ],
   "source": [
    "formalizations['Vi']('walk')('john')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
