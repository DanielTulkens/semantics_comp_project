{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "import sys \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> DP VP\n",
    "    DP -> Det NP | NP | DP Conj DP\n",
    "    NP -> N | PropN | Adj NP | NP PP\n",
    "    VP -> Vi | Vt  | Vbar DP | Vbar DP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P DP\n",
    "    Det -> 'a' | 'an' | 'the' | 'every'| 'some' | 'any'\n",
    "    P -> 'with' | 'in' | 'on' | 'to' | 'without' | 'from'\n",
    "    Conj -> 'and' | 'or' | 'but'\n",
    "\n",
    "\n",
    "    N -> 'boy' | 'student' | 'girl' | 'class' | 'book' | 'teacher'\n",
    "    PropN -> 'john' | 'mary'\n",
    "    Adj -> 'eager' | 'smart'\n",
    "    Vi -> 'walks' | 'passed' \n",
    "    Vt -> 'sees' | 'teaches'\n",
    "    Adv -> 'eagerly' | 'well'\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ 'John sees Mary', 'A student walks', 'Some girl sees every boy','Every eager student passed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (DP (Det some) (NP (N girl)))\n",
      "  (VP (Vbar (Vt sees)) (DP (Det every) (NP (N boy)))))\n"
     ]
    }
   ],
   "source": [
    "# sentence = random.choice(sentences)\n",
    "sentence = sentences[2]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    print(parse_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               S                \n",
      "       ________|_____            \n",
      "      |              VP         \n",
      "      |         _____|____       \n",
      "      DP       |          DP    \n",
      "  ____|___     |      ____|___   \n",
      " |        NP  Vbar   |        NP\n",
      " |        |    |     |        |  \n",
      "Det       N    Vt   Det       N \n",
      " |        |    |     |        |  \n",
      "some     girl sees every     boy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Vbar (Vt sees))\n",
      "(DP (Det some) (NP (N girl)))\n",
      "           S         \n",
      "      _____|______    \n",
      "     DP           |  \n",
      "  ___|_____       |   \n",
      " |         NP     VP \n",
      " |         |      |   \n",
      "Det        N      Vi \n",
      " |         |      |   \n",
      " a      student walks\n",
      "\n",
      "(Det a)\n",
      "\n",
      "\n",
      "(S (DP (Det a) (NP (N student))) (VP (Vi walks)))\n",
      "(DP (Det a) (NP (N student)))\n",
      "(Det a)\n",
      "(NP (N student))\n",
      "(N student)\n",
      "(VP (Vi walks))\n",
      "(Vi walks)\n",
      "\n",
      "\n",
      "()\n",
      "(0,)\n",
      "(0, 0)\n",
      "(0, 0, 0)\n",
      "(0, 1)\n",
      "(0, 1, 0)\n",
      "(0, 1, 0, 0)\n",
      "(1,)\n",
      "(1, 0)\n",
      "(1, 0, 0)\n",
      "\n",
      "\n",
      "(0, 0, 0)\n",
      "(0, 1, 0, 0)\n",
      "(1, 0, 0)\n",
      "\n",
      "\n",
      "(0, 0, 0)\n",
      "(0, 0)\n",
      "(0, 1, 0, 0)\n",
      "(0, 1, 0)\n",
      "(0, 1)\n",
      "(0,)\n",
      "(1, 0, 0)\n",
      "(1, 0)\n",
      "(1,)\n",
      "()\n",
      "\n",
      "\n",
      "           S         \n",
      "      _____|______    \n",
      "     DP           |  \n",
      "  ___|_____       |   \n",
      " |         NP     VP \n",
      " |         |      |   \n",
      "Det        N      Vi \n",
      " |         |      |   \n",
      " a      student walks\n",
      "\n",
      "None\n",
      "(1, 0, 0)\n",
      "(0,)\n",
      "       S            \n",
      "   ____|____         \n",
      "  |         VP      \n",
      "  |     ____|____    \n",
      "  DP   |         DP \n",
      "  |    |         |   \n",
      "  NP  Vbar       NP \n",
      "  |    |         |   \n",
      "PropN  Vt      PropN\n",
      "  |    |         |   \n",
      " john sees      mary\n",
      "\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "#select the verb for the sentence 'john sees mary' \n",
    "print(parse_tree[1,0])\n",
    "#select the subject for the sentence 'john sees mary'\n",
    "print(parse_tree[0])\n",
    "#select the determiner for sentence 'A student walks'\n",
    "sentence = sentences[1]\n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()\n",
    "print(parse_tree[0,0])\n",
    "print('\\n' )\n",
    "\n",
    "#practice iterating\n",
    "for subtree in parse_tree.subtrees(): \n",
    "    print(subtree)\n",
    "print('\\n' )\n",
    "for pos in parse_tree.treepositions(): \n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"leaves\"):\n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"postorder\"):\n",
    "  print(pos)\n",
    "print('\\n')\n",
    "\n",
    "#get parent node \n",
    "\n",
    "def get_parent_node(child_tuple): \n",
    "    if len(child_tuple) >= 1: \n",
    "        parent_node = child_tuple[:-1]\n",
    "        return parent_node\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#get verb tuple \n",
    "def get_verb_tuple(tree):\n",
    "    for node in tree.treepositions(order=\"leaves\"):\n",
    "        if tree[get_parent_node(node)].label() in [\"Vi\", \"Vt\"]:\n",
    "            return node\n",
    "\n",
    "verb = get_verb_tuple(parse_tree) #calling the get verb \n",
    "print(parse_tree.pretty_print())\n",
    "print(verb)\n",
    "\n",
    "\n",
    "\n",
    "# #Define a function that takes a parse tree, and returns the position of the subject DP.\n",
    "def get_subj_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] != VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "dp = get_subj_pos(parse_tree)\n",
    "print(dp)\n",
    "\n",
    "\n",
    "#Define a function that takes a parse tree, and returns the position of the object DP if one exists, and None otherwise\n",
    "def get_object_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] == VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "obj = get_object_pos(parse_tree)\n",
    "print(obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = { \n",
    "    'John sees Mary' : 'SEES(j,m)', \n",
    "    'A student walks': 'some x [WALK(x)]', \n",
    "    'Some girl sees every boy': 'all y some x [(GIRL(x) ∧ BOY(y)) → SEES(x, y))]',\n",
    "    'Every eager student passed': ''}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {\n",
    "    'P': (\n",
    "        'with',\n",
    "        'in',\n",
    "        'on',\n",
    "        'to',\n",
    "        'without',\n",
    "        'from'\n",
    "    ),\n",
    "    'N': (\n",
    "        'boy',\n",
    "        'student',\n",
    "        'girl',\n",
    "        'class',\n",
    "        'book',\n",
    "        'teacher'\n",
    "    ),\n",
    "    'PropN': (\n",
    "        'john',\n",
    "        'mary'\n",
    "    ),\n",
    "    'Trace': (\n",
    "        't1',\n",
    "        't2',\n",
    "        't3'\n",
    "    ),\n",
    "    'Vi': (\n",
    "        'walks',\n",
    "        'passed'\n",
    "    ),\n",
    "    'Vt': (\n",
    "        'sees',\n",
    "        'teaches'\n",
    "    ),\n",
    "    'Adj': (\n",
    "        'eager',\n",
    "        'smart'\n",
    "    ),\n",
    "    'Adv': (\n",
    "        'eagerly',\n",
    "        'well'\n",
    "    ),\n",
    "    'Det': (\n",
    "        'a',\n",
    "        'an',\n",
    "        'the',\n",
    "        'every',\n",
    "        'some',\n",
    "        'any'\n",
    "    ),\n",
    "    'Conj': (\n",
    "        'and',\n",
    "        'or',\n",
    "        'but'\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class would create an object storing both the representation of an element, and its typing information\n",
    "class Formalization:\n",
    "    def __init__(self, formula, type_hint, type_=None):\n",
    "        self.formula = formula\n",
    "        self.type = type_hint\n",
    "        self.t = type_\n",
    "        if type(type_hint) == tuple:\n",
    "            self.selected = type_hint[0]\n",
    "            self.returned = type_hint[1]\n",
    "        else:\n",
    "            self.selected = None\n",
    "\n",
    "    def application(self, argument):\n",
    "        if argument.type == self.selected:\n",
    "            resulting_formula = self.formula(argument.formula)\n",
    "            return Formalization(resulting_formula, self.returned, self.t)\n",
    "\n",
    "\n",
    "# this dictionary contains functions to generate lexical entries for different parts of speech.\n",
    "formalizations = {\n",
    "    'PropN': lambda name: Formalization(\n",
    "        name,\n",
    "        'e', 'PropN'\n",
    "    ),\n",
    "    'Trace': lambda name: Formalization(\n",
    "        name,\n",
    "        'e', 'Trace'\n",
    "    ),\n",
    "    'N': lambda noun: Formalization(\n",
    "        lambda x: f'{noun.upper()}({x})',\n",
    "        ('e', 't'), 'N'\n",
    "    ),\n",
    "    'Vi': lambda verb: Formalization(\n",
    "        lambda x: f'{verb.upper()}({x})',\n",
    "        ('e', 't'), 'Vi'\n",
    "    ),\n",
    "    'Vt': lambda verb: Formalization(\n",
    "        lambda y: lambda x: f'{verb.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't')), 'Vt'\n",
    "    ),\n",
    "    'Adj': lambda adjective: Formalization(\n",
    "        lambda P: lambda x: f'{adjective.upper()}({x}) ^ {P(x)}',\n",
    "        (('e', 't'), ('e', 't')), 'Adj'\n",
    "    ),\n",
    "    'Adv': lambda adverb: Formalization(\n",
    "        lambda P: lambda x: f'{adverb.upper()}({P(x)})',\n",
    "        (('e', 't'), ('e', 't')), 'Adv'\n",
    "    ),\n",
    "    'P': lambda preposition: Formalization(\n",
    "        lambda x: lambda y: f'{preposition.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't')), 'P'\n",
    "    ),\n",
    "    'existential': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'Exists x[{P(\"x\")} ^ {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't')), 'existential'\n",
    "    ),\n",
    "    'universal': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'All x[{P(\"x\")} -> {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't')), 'universal'\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def generate_lexicon(vocab, translations):\n",
    "    lexicon = {}\n",
    "    for part_of_speech, entries in vocab.items():\n",
    "        if part_of_speech in translations.keys():\n",
    "            lexicon.update({part_of_speech: {word: translations[part_of_speech](word) for word in entries}})\n",
    "        elif type(entries) == dict:\n",
    "            lexicon[part_of_speech] = {}\n",
    "            for subtype, words in entries.items():\n",
    "                lexicon[part_of_speech].update({word: translations[subtype](word) for word in words})\n",
    "        else:\n",
    "            lexicon.update({part_of_speech: {word: Formalization(word, 'e') for word in entries}})\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def lexicon_to_terminals(lexicon):\n",
    "    terminal_rules = ''\n",
    "    for part_of_speech in lexicon.keys():\n",
    "        terminals_string = \" | \".join([\"'\" + word + \"'\" for word in lexicon[part_of_speech].keys()])\n",
    "        terminal_rules += (part_of_speech + ' -> ' + terminals_string + '\\n\\t')\n",
    "    return terminal_rules\n",
    "\n",
    "\n",
    "extensional_lexicon = generate_lexicon(vocabulary, formalizations)\n",
    "\n",
    "terminals_entries = lexicon_to_terminals(extensional_lexicon)\n",
    "\n",
    "extensional_grammar = f\"\"\"\n",
    "    S -> NP VP | Trace VP\n",
    "    NP -> Det Nom | PropN | Trace\n",
    "    Nom -> N  | Adj Nom | Nom PP\n",
    "    VP -> Vi | Vt  | Vbar NP | Vbar NP PP | Adv VP | VP Adv | VP Conj VP | V AdvP | Vbar Trace\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P NP\n",
    "    {terminals_entries}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           S         \n",
      "      _____|______    \n",
      "     DP           |  \n",
      "  ___|_____       |   \n",
      " |         NP     VP \n",
      " |         |      |   \n",
      "Det        N      Vi \n",
      " |         |      |   \n",
      " a      student walks\n",
      "\n",
      "help\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Exists x[STUDENT(x) ^ WALKS(x)]'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existentials = ['a', 'some', 'an']\n",
    "universal = ['every']\n",
    "\n",
    "def check_quantificational_children(result, node):\n",
    "    return result[node + (1,)].t in ['existential', 'universal'] or result[node + (0,)].t in ['existential', 'universal']\n",
    "\n",
    "def translate_to_logic(tree = nltk.Tree):\n",
    "    result = {}\n",
    "    prev_was_leave = False\n",
    "    leaf = ''\n",
    "    root_cause = None\n",
    "    for node in tree.treepositions(order='postorder'):\n",
    "        if isinstance(tree[node], nltk.Tree):\n",
    "            if len(tree[node]) > 1:\n",
    "                if tree[node].label() == 'S':\n",
    "                    if check_quantificational_children(result, node):\n",
    "                        print(\"help\")\n",
    "                        result[node] = result[node + (0,)].application(result[node + (1,)])\n",
    "                    else:\n",
    "                        print(result[node + (0,)])\n",
    "                        result[node] = result[node + (1,)].application(result[node + (0,)])\n",
    "                else:\n",
    "                    result[node] = result[node + (0,)].application(result[node + (1,)])\n",
    "                    if tree[node].label() == 'VP' and check_quantificational_children(result, node):\n",
    "                        return None\n",
    "            else:\n",
    "                if prev_was_leave:\n",
    "                    if leaf in existentials:\n",
    "                        applier = 'existential'\n",
    "                    elif leaf in universal:\n",
    "                        applier = 'universal'\n",
    "                    else:\n",
    "                        applier = tree[node].label()\n",
    "                    result[node] = formalizations[applier](leaf)\n",
    "                    root_cause = result[node]\n",
    "                    prev_was_leave = False\n",
    "                else:\n",
    "                    result[node] = root_cause\n",
    "        else:\n",
    "            prev_was_leave = True\n",
    "            leaf = tree[node]\n",
    "    return result\n",
    "sentence = sentences[1]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "res = translate_to_logic(parse_tree)\n",
    "res[()].formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): <__main__.Formalization at 0x1a182409c50>,\n",
       " (0, 1, 0): <__main__.Formalization at 0x1a182234b50>,\n",
       " (0, 1): <__main__.Formalization at 0x1a182234b50>,\n",
       " (0,): <__main__.Formalization at 0x1a1821bba50>,\n",
       " (1, 0): <__main__.Formalization at 0x1a1821bbb90>,\n",
       " (1,): <__main__.Formalization at 0x1a1821bbb90>,\n",
       " (): <__main__.Formalization at 0x1a182214fd0>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('e', 't'), (('e', 't'), 't')) <function <lambda>.<locals>.<lambda> at 0x000001A182238400> (0, 0)\n",
      "('e', 't') <function <lambda>.<locals>.<lambda> at 0x000001A1821EA8E0> (0, 1, 0)\n",
      "('e', 't') <function <lambda>.<locals>.<lambda> at 0x000001A1821EA8E0> (0, 1)\n",
      "(('e', 't'), 't') <function <lambda>.<locals>.<lambda>.<locals>.<lambda> at 0x000001A1821E8B80> (0,)\n",
      "('e', 't') <function <lambda>.<locals>.<lambda> at 0x000001A1821E8040> (1, 0)\n",
      "('e', 't') <function <lambda>.<locals>.<lambda> at 0x000001A1821E8040> (1,)\n",
      "t Exists x[STUDENT(x) ^ WALKS(x)] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(r.type, r.formula, k) for k, r in res.items() if r is not None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               S                \n",
      "       ________|_____            \n",
      "      |              VP         \n",
      "      |         _____|____       \n",
      "      DP       |          DP    \n",
      "  ____|___     |      ____|___   \n",
      " |        NP  Vbar   |        NP\n",
      " |        |    |     |        |  \n",
      "Det       N    Vt   Det       N \n",
      " |        |    |     |        |  \n",
      "some     girl sees every     boy\n",
      "\n",
      "{(0,): Tree('DP', [Tree('Det', ['some']), Tree('NP', [Tree('N', ['girl'])])]), (1, 1): Tree('DP', [Tree('Det', ['every']), Tree('NP', [Tree('N', ['boy'])])])}\n",
      "First Version \n",
      "\n",
      "after trace added \n",
      "\n",
      "            S               \n",
      "   _________|____            \n",
      "  |              VP         \n",
      "  |     _________|____       \n",
      "  |    |              DP    \n",
      "  |    |          ____|___   \n",
      "  |   Vbar       |        NP\n",
      "  |    |         |        |  \n",
      "Trace  Vt       Det       N \n",
      "  |    |         |        |  \n",
      "  t1  sees     every     boy\n",
      "\n",
      "                S1                        \n",
      "       _________|_________                 \n",
      "      |                   S               \n",
      "      |          _________|____            \n",
      "      |         |              VP         \n",
      "      |         |     _________|____       \n",
      "     DP1        |    |              DP    \n",
      "  ____|___      |    |          ____|___   \n",
      " |        NP    |   Vbar       |        NP\n",
      " |        |     |    |         |        |  \n",
      "Det       N   Trace  Vt       Det       N \n",
      " |        |     |    |         |        |  \n",
      "some     girl   t1  sees     every     boy\n",
      "\n",
      "after trace added \n",
      "\n",
      "                S1                \n",
      "       _________|____              \n",
      "      |              S            \n",
      "      |          ____|____         \n",
      "     DP1        |         VP      \n",
      "  ____|___      |     ____|____    \n",
      " |        NP    |   Vbar       |  \n",
      " |        |     |    |         |   \n",
      "Det       N   Trace  Vt      Trace\n",
      " |        |     |    |         |   \n",
      "some     girl   t1  sees       t2 \n",
      "\n",
      "                        S2                      \n",
      "        ________________|_____                   \n",
      "       |                      S1                \n",
      "       |             _________|____              \n",
      "       |            |              S            \n",
      "       |            |          ____|____         \n",
      "      DP2          DP1        |         VP      \n",
      "   ____|___     ____|___      |     ____|____    \n",
      "  |        NP  |        NP    |   Vbar       |  \n",
      "  |        |   |        |     |    |         |   \n",
      " Det       N  Det       N   Trace  Vt      Trace\n",
      "  |        |   |        |     |    |         |   \n",
      "every     boy some     girl   t1  sees       t2 \n",
      "\n",
      "Second Version \n",
      "\n",
      "(DP (Det every) (NP (N boy)))\n",
      "after trace added \n",
      "\n",
      "               S                \n",
      "       ________|________         \n",
      "      DP                VP      \n",
      "  ____|___          ____|____    \n",
      " |        NP      Vbar       |  \n",
      " |        |        |         |   \n",
      "Det       N        Vt      Trace\n",
      " |        |        |         |   \n",
      "some     girl     sees       t1 \n",
      "\n",
      "               S1                             \n",
      "        _______|_____________                  \n",
      "       |                     S                \n",
      "       |             ________|________         \n",
      "      DP1           DP                VP      \n",
      "   ____|___     ____|___          ____|____    \n",
      "  |        NP  |        NP      Vbar       |  \n",
      "  |        |   |        |        |         |   \n",
      " Det       N  Det       N        Vt      Trace\n",
      "  |        |   |        |        |         |   \n",
      "every     boy some     girl     sees       t1 \n",
      "\n",
      "(DP (Det some) (NP (N girl)))\n",
      "after trace added \n",
      "\n",
      "                 S1                             \n",
      "        _________|_____________                  \n",
      "       |                       S                \n",
      "       |               ________|________         \n",
      "       |              DP                VP      \n",
      "       |          ____|___          ____|____    \n",
      "      DP1        |        NP      Vbar       |  \n",
      "   ____|____     |        |        |         |   \n",
      " Det      Trace Det       N        Vt      Trace\n",
      "  |         |    |        |        |         |   \n",
      "every       t2  some     girl     sees       t1 \n",
      "\n",
      "      S2                                            \n",
      "  ____|______________                                \n",
      " |                   S1                             \n",
      " |          _________|_____________                  \n",
      " |         |                       S                \n",
      " |         |               ________|________         \n",
      " |         |              DP                VP      \n",
      " |         |          ____|___          ____|____    \n",
      "DP2       DP1        |        NP      Vbar       |  \n",
      " |     ____|____     |        |        |         |   \n",
      " N   Det      Trace Det       N        Vt      Trace\n",
      " |    |         |    |        |        |         |   \n",
      "boy every       t2  some     girl     sees       t1 \n",
      "\n",
      "basic tree:\n",
      "\n",
      "       S            \n",
      "   ____|____         \n",
      "  |         VP      \n",
      "  |     ____|____    \n",
      "  |   Vbar       |  \n",
      "  |    |         |   \n",
      "Trace  Vt      Trace\n",
      "  |    |         |   \n",
      "  t1  sees       t2 \n",
      "\n",
      "<__main__.Formalization object at 0x000001A1820E2290>\n",
      "SEES(t1, t2)\n",
      "{'t1': (1, 1, 0, 0), 't2': (1, 1, 1, 1, 0)}\n",
      "<function <lambda>.<locals>.<lambda>.<locals>.<lambda> at 0x000001A1820DC220>\n",
      "      S      \n",
      "      |       \n",
      "      DP     \n",
      "  ____|___    \n",
      " |        NP \n",
      " |        |   \n",
      "Det       N  \n",
      " |        |   \n",
      "some     girl\n",
      "\n",
      "None\n",
      "<function <lambda>.<locals>.<lambda>.<locals>.<lambda> at 0x000001A1820DE3E0>\n",
      "       S     \n",
      "       |      \n",
      "       DP    \n",
      "   ____|___   \n",
      "  |        NP\n",
      "  |        |  \n",
      " Det       N \n",
      "  |        |  \n",
      "every     boy\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quantifier_raising(tree, nb, position):\n",
    "    tree_ = tree.copy(deep=True)\n",
    "    for i in range(nb-1):\n",
    "        newposition = position + (1,)\n",
    "        position = newposition\n",
    "        # print(f'the position is {position}')\n",
    "    \n",
    "    qp = tree_[position]\n",
    "    tree_[position] = Tree('Trace', [f't{nb}'])\n",
    "    print('after trace added \\n')\n",
    "    tree_.pretty_print()\n",
    "\n",
    "    tree_ = nltk.Tree(f'S{nb}',[qp, tree_])\n",
    "    tree_[0].set_label(f'DP{nb}')\n",
    "    return tree_\n",
    "\n",
    "\n",
    "def raiser(tree=nltk.Tree):\n",
    "    tree_list = []\n",
    "    tree1 = tree.copy(deep=True)\n",
    "    quant_dict = {}\n",
    "    for node in tree1.treepositions(order='postorder'):\n",
    "        if (tree1[node] in existentials) or (tree1[node] in universal):\n",
    "            quant_dict[node[:-2]] = tree1[node[:-2]]\n",
    "    print(quant_dict)\n",
    "    nb = 0\n",
    "    print('First Version \\n')\n",
    "    for key in quant_dict.keys():\n",
    "        #print(quant_dict[key])\n",
    "      \n",
    "        nb += 1\n",
    "        tree1 = quantifier_raising(tree1, nb, key)\n",
    "        tree1.pretty_print()\n",
    "    tree_list.append(tree1)\n",
    "    if len(quant_dict) == 2: # if there is another QP we will generate a new possible structure\n",
    "        tree2 = tree.copy(deep=True)\n",
    "        nb = 0\n",
    "        print('Second Version \\n') \n",
    "        for key in reversed(quant_dict.keys()):\n",
    "            print(quant_dict[key])\n",
    "            nb += 1\n",
    "            tree2 = quantifier_raising(tree2, nb, key) # still some things going wrong, I'll try to fix it\n",
    "            tree2.pretty_print()\n",
    "    tree_list.append(tree2)\n",
    "    return tree1\n",
    "\n",
    "\n",
    "\n",
    "## Assignment 8\n",
    "def quantifier_logic(tree = nltk.Tree):\n",
    "    traces = {}\n",
    "    treeq = tree.copy(deep=True)\n",
    "    for node in tree.treepositions(order=\"postorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree):\n",
    "            if len(tree[node]) > 1:\n",
    "                if tree[node].label() == 'S':\n",
    "                    basic_tree = tree[node]\n",
    "                    print('basic tree:\\n')\n",
    "                    basic_tree.pretty_print()\n",
    "                    base_logic = translate_to_logic(basic_tree) # get the logcial form from below the raised quantifiers\n",
    "                    print(base_logic[()].formula)\n",
    "            if tree[node].label() == 'Trace':\n",
    "                traces[tree[node,0]] = node + (0,) # collect traces positions and names in a dictionary\n",
    "    print(traces)\n",
    "    for trace in traces.keys(): # now we will slowly do lambda abstraction per raised quantifier\n",
    "        trace_number = trace[-1]\n",
    "        for node in tree.treepositions(order=\"postorder\"):\n",
    "            if isinstance(tree[node], nltk.Tree):\n",
    "                if len(tree[node]) > 1:\n",
    "                    if tree[node].label() == f'DP{trace_number}':\n",
    "                        subtree = tree[node].copy(deep=True)\n",
    "                        subtree.set_label('DP')\n",
    "                        new_tree = nltk.Tree('S', [subtree])\n",
    "                        sub_logic = translate_to_logic(subtree)\n",
    "                        print(sub_logic[()].formula) # doesn't work?\n",
    "                        new_tree.pretty_print()\n",
    "\n",
    "        lambda_abstraction = lambda trace: f'{base_logic}'\n",
    "        # basically what I want to do here is have a variable (such as) 'x' replacing the position of trace in the base logic\n",
    "        \n",
    "        result = sub_logic[()].application(base_logic[()]) # Not sure what I'm doing here tbh -> I want to apply the base logic to the quantifier phrase\n",
    "        print(result) # gives none\n",
    "    # repeat for next trace -> have to make sure that we get a new variable for the next quantifier phrase (otherwise subject and object are referring to the same thing)\n",
    "    logic = ...\n",
    "    return logic\n",
    "\n",
    "sentence = sentences[2]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "parse_tree = raiser(parse_tree)\n",
    "\n",
    "quantifier_logic(parse_tree)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######\n",
    "# for translation to logic: translate up until first QP        ( SEE(t1,t2) )\n",
    "# before QP apply lambda abstraction (lambda trace number)     ( lambda t1 SEE(t1,t2) )\n",
    "# apply logical form QP to translation up till then ( (lambda Q some x[GIRL(x) ^ Q(x)] )(lambda t1 (SEE(t1, t2))) )\n",
    "# give translation the variable that is inside QP () to fill lambda with (some x[GIRL(x)^(lambda t1 (SEE(t1, t2))) (x) ])\n",
    "# fill up lambda trace: (some x[GIRL(x)^(SEE(x, t2))])\n",
    "######\n",
    "# repeat for next QP:\n",
    "######\n",
    "# lambda t2 some x[GIRL(x)^(SEE(x,t2))]\n",
    "# (lambda Q all y[BOY(y) -> Q(y)]) (lambda t2 some x[GIRL(x)^(SEE(x,t2))])\n",
    "# all y[BOY(y) -> (lambda t2 some x[GIRL(x)^(SEE(x,t2))])(y)]) \n",
    "# all y[BOY(y) -> some x[GIRL(x)^(SEE(x,y))] ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 11\n",
    "**scope islands** \n",
    "# Main principles:\n",
    "- Every quantified phrase must properly bind a variable\n",
    "- Every variable in an argument position must be properly bound [c-commanded\n",
    "by a binding phrase]\n",
    "\n",
    "- Island constraint 1: Following these conditions, quantifier phrases cannot be raised out of wh-phrases:\n",
    "- ∗Which man in some city did you meet?\n",
    "- [S’ [Which man in ti]j [S [some city]i [S did you meet tj]]]\n",
    "- First Quantifier Raising ([some city]i moves to higher S node)\n",
    "- Wh-phrase moves up (wh-movement) to S'\n",
    "- quantifier no longer c-commands variable\n",
    "- therefore the trace is no longer properly bound\n",
    "\n",
    "- Everything can be summarized by the **Subjacency Condition**:\n",
    "- Move cannot relate two positions across two bounding notes. \n",
    "- Bounding nodes are CP, TP, DP (when no complement of V)\n",
    "\n",
    "\n",
    "> Some man has met every cheer-leader.\n",
    "- There is a person who has met every single cheer-leader\n",
    "- For every cheer-leader, there is a man who has met them\n",
    "\n",
    "> Some man regretted the fact that Bill had met every cheer-leader.\n",
    "Every cheer-leader cannot take scope over \"some man\" -> would imply moving over CP and TP (=2 bounding nodes) - complex noun phrase constraint\n",
    "- this means that we cannot derive the meaning: for every cheer-leader, there is a man who regrets that Bill has met them\n",
    "\n",
    "same goes for:\n",
    ">  Someone believes that Mary is dating every student\n",
    "- cannot derive \"for every student, there is someone who believes that Mary is dating them\"\n",
    "- this is not due to subjacency condition (moves over TP but that is sister of DP, and then over another TP)\n",
    "- paper says: QR out of finite clauses is blocked\n",
    "\n",
    "(https://www.ling.uni-potsdam.de/~zimmermann/teaching/Syntax-Semantic_Interface/Handouts/May-QuantifierRaising.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
