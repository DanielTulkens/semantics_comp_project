{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "import sys \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> DP VP\n",
    "    DP -> Det NP | NP | DP Conj DP\n",
    "    NP -> N | PropN | Adj NP | NP PP\n",
    "    VP -> Vi | Vt  | Vbar DP | Vbar DP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P DP\n",
    "    Det -> 'a' | 'an' | 'the' | 'every'| 'some' | 'any'\n",
    "    P -> 'with' | 'in' | 'on' | 'to' | 'without' | 'from'\n",
    "    Conj -> 'and' | 'or' | 'but'\n",
    "\n",
    "\n",
    "    N -> 'boy' | 'student' | 'girl' | 'class' | 'book' | 'teacher'\n",
    "    PropN -> 'john' | 'mary'\n",
    "    Adj -> 'eager' | 'smart'\n",
    "    Vi -> 'walks' | 'passed' \n",
    "    Vt -> 'sees' | 'teaches'\n",
    "    Adv -> 'eagerly' | 'well'\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ 'John sees Mary', 'A student walks', 'Some girl sees every boy','Every eager student passed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = random.choice(sentences)\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    print(parse_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                \n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "if not parse_trees:\n",
    "    print(\"No parse tree found.\")\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the verb for the sentence 'john sees mary' \n",
    "print(parse_tree[1,0])\n",
    "#select the subject for the sentence 'john sees mary'\n",
    "print(parse_tree[0])\n",
    "#select the determiner for sentence 'A student walks'\n",
    "sentence = sentences[1]\n",
    "tokens = sentence.lower().split()\n",
    "parse_trees = parser.parse(tokens)\n",
    "for parse_tree in parse_trees:\n",
    "    parse_tree.pretty_print()\n",
    "print(parse_tree[0,0])\n",
    "print('\\n' )\n",
    "\n",
    "#practice iterating\n",
    "for subtree in parse_tree.subtrees(): \n",
    "    print(subtree)\n",
    "print('\\n' )\n",
    "for pos in parse_tree.treepositions(): \n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"leaves\"):\n",
    "    print(pos)\n",
    "print('\\n')\n",
    "for pos in parse_tree.treepositions(order=\"postorder\"):\n",
    "  print(pos)\n",
    "print('\\n')\n",
    "\n",
    "#get parent node \n",
    "\n",
    "def get_parent_node(child_tuple): \n",
    "    if len(child_tuple) >= 1: \n",
    "        parent_node = child_tuple[:-1]\n",
    "        return parent_node\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#get verb tuple \n",
    "def get_verb_tuple(tree):\n",
    "    for node in tree.treepositions(order=\"leaves\"):\n",
    "        if tree[get_parent_node(node)].label() in [\"Vi\", \"Vt\"]:\n",
    "            return node\n",
    "\n",
    "verb = get_verb_tuple(parse_tree) #calling the get verb \n",
    "print(parse_tree.pretty_print())\n",
    "print(verb)\n",
    "\n",
    "\n",
    "\n",
    "# #Define a function that takes a parse tree, and returns the position of the subject DP.\n",
    "def get_subj_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] != VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "dp = get_subj_pos(parse_tree)\n",
    "print(dp)\n",
    "\n",
    "\n",
    "#Define a function that takes a parse tree, and returns the position of the object DP if one exists, and None otherwise\n",
    "def get_object_pos(tree):\n",
    "    VP_pos = (-1,)\n",
    "    for node in tree.treepositions(order=\"preorder\"):\n",
    "        if isinstance(tree[node], nltk.Tree): #Check if node has children\n",
    "            if tree[node].label() == \"VP\":\n",
    "                VP_pos = node\n",
    "            if node[:len(VP_pos)] == VP_pos and tree[node].label() == \"DP\":\n",
    "                return node\n",
    "\n",
    "sentence = sentences[0]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "obj = get_object_pos(parse_tree)\n",
    "print(obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = { \n",
    "    'John sees Mary' : 'SEES(j,m)', \n",
    "    'A student walks': 'some x [WALK(x)]', \n",
    "    'Some girl sees every boy': 'all y some x [(GIRL(x) ∧ BOY(y)) → SEES(x, y))]',\n",
    "    'Every eager student passed': ''}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {\n",
    "    'P': (\n",
    "        'with',\n",
    "        'in',\n",
    "        'on',\n",
    "        'to',\n",
    "        'without',\n",
    "        'from'\n",
    "    ),\n",
    "    'N': (\n",
    "        'boy',\n",
    "        'student',\n",
    "        'girl',\n",
    "        'class',\n",
    "        'book',\n",
    "        'teacher'\n",
    "    ),\n",
    "    'PropN': (\n",
    "        'john',\n",
    "        'mary'\n",
    "    ),\n",
    "    'Vi': (\n",
    "        'walks',\n",
    "        'passed'\n",
    "    ),\n",
    "    'Vt': (\n",
    "        'sees',\n",
    "        'teaches'\n",
    "    ),\n",
    "    'Adj': (\n",
    "        'eager',\n",
    "        'smart'\n",
    "    ),\n",
    "    'Adv': (\n",
    "        'eagerly',\n",
    "        'well'\n",
    "    ),\n",
    "    'Det': (\n",
    "        'a',\n",
    "        'an',\n",
    "        'the',\n",
    "        'every',\n",
    "        'some',\n",
    "        'any'\n",
    "    ),\n",
    "    'Conj': (\n",
    "        'and',\n",
    "        'or',\n",
    "        'but'\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class would create an object storing both the representation of an element, and its typing information\n",
    "class Formalization:\n",
    "    def __init__(self, formula, type_hint, type_=None):\n",
    "        self.formula = formula\n",
    "        self.type = type_hint\n",
    "        self.t = type_\n",
    "        if type(type_hint) == tuple:\n",
    "            self.selected = type_hint[0]\n",
    "            self.returned = type_hint[1]\n",
    "        else:\n",
    "            self.selected = None\n",
    "\n",
    "    def application(self, argument):\n",
    "        if argument.type == self.selected:\n",
    "            resulting_formula = self.formula(argument.formula)\n",
    "            return Formalization(resulting_formula, self.returned, self.t)\n",
    "\n",
    "\n",
    "# this dictionary contains functions to generate lexical entries for different parts of speech.\n",
    "formalizations = {\n",
    "    'PropN': lambda name: Formalization(\n",
    "        name,\n",
    "        'e', 'PropN'\n",
    "    ),\n",
    "    'N': lambda noun: Formalization(\n",
    "        lambda x: f'{noun.upper()}({x})',\n",
    "        ('e', 't'), 'N'\n",
    "    ),\n",
    "    'Vi': lambda verb: Formalization(\n",
    "        lambda x: f'{verb.upper()}({x})',\n",
    "        ('e', 't'), 'Vi'\n",
    "    ),\n",
    "    'Vt': lambda verb: Formalization(\n",
    "        lambda y: lambda x: f'{verb.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't')), 'Vt'\n",
    "    ),\n",
    "    'Adj': lambda adjective: Formalization(\n",
    "        lambda P: lambda x: f'{adjective.upper()}({x}) ^ {P(x)}',\n",
    "        (('e', 't'), ('e', 't')), 'Adj'\n",
    "    ),\n",
    "    'Adv': lambda adverb: Formalization(\n",
    "        lambda P: lambda x: f'{adverb.upper()}({P(x)})',\n",
    "        (('e', 't'), ('e', 't')), 'Adv'\n",
    "    ),\n",
    "    'P': lambda preposition: Formalization(\n",
    "        lambda x: lambda y: f'{preposition.upper()}({x}, {y})',\n",
    "        ('e', ('e', 't')), 'P'\n",
    "    ),\n",
    "    'existential': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'Exists x[{P(\"x\")} ^ {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't')), 'existential'\n",
    "    ),\n",
    "    'universal': lambda _: Formalization(\n",
    "        lambda P: lambda Q: f'All x[{P(\"x\")} -> {Q(\"x\")}]',\n",
    "        (('e', 't'), (('e', 't'), 't')), 'universal'\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def generate_lexicon(vocab, translations):\n",
    "    lexicon = {}\n",
    "    for part_of_speech, entries in vocab.items():\n",
    "        if part_of_speech in translations.keys():\n",
    "            lexicon.update({part_of_speech: {word: translations[part_of_speech](word) for word in entries}})\n",
    "        elif type(entries) == dict:\n",
    "            lexicon[part_of_speech] = {}\n",
    "            for subtype, words in entries.items():\n",
    "                lexicon[part_of_speech].update({word: translations[subtype](word) for word in words})\n",
    "        else:\n",
    "            lexicon.update({part_of_speech: {word: Formalization(word, 'e') for word in entries}})\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def lexicon_to_terminals(lexicon):\n",
    "    terminal_rules = ''\n",
    "    for part_of_speech in lexicon.keys():\n",
    "        terminals_string = \" | \".join([\"'\" + word + \"'\" for word in lexicon[part_of_speech].keys()])\n",
    "        terminal_rules += (part_of_speech + ' -> ' + terminals_string + '\\n\\t')\n",
    "    return terminal_rules\n",
    "\n",
    "\n",
    "extensional_lexicon = generate_lexicon(vocabulary, formalizations)\n",
    "\n",
    "terminals_entries = lexicon_to_terminals(extensional_lexicon)\n",
    "\n",
    "extensional_grammar = f\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det Nom | PropN\n",
    "    Nom -> N  | Adj Nom | Nom PP\n",
    "    VP -> Vi | Vt  | Vbar NP | Vbar NP PP | Adv VP | VP Adv | VP Conj VP | V AdvP\n",
    "    Vbar -> Vi | Vt\n",
    "    AdvP -> Adv P\n",
    "    PP -> P NP\n",
    "    {terminals_entries}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existentials = ['a', 'some', 'an']\n",
    "universal = ['every']\n",
    "\n",
    "def check_quantificational_children(result, node):\n",
    "    return result[node + (1,)].t in ['existential', 'universal'] or result[node + (0,)].t in ['existential', 'universal']\n",
    "\n",
    "def translate_to_logic(tree = nltk.Tree):\n",
    "    result = {}\n",
    "    prev_was_leave = False\n",
    "    leaf = ''\n",
    "    root_cause = None\n",
    "    for node in tree.treepositions(order='postorder'):\n",
    "        if isinstance(tree[node], nltk.Tree):\n",
    "            if len(tree[node]) > 1:\n",
    "                if tree[node].label() == 'S':\n",
    "                    if check_quantificational_children(result, node):\n",
    "                        print(\"help\")\n",
    "                        result[node] = result[node + (0,)].application(result[node + (1,)])\n",
    "                    else:\n",
    "                        print(result[node + (0,)])\n",
    "                        result[node] = result[node + (1,)].application(result[node + (0,)])\n",
    "                else:\n",
    "                    result[node] = result[node + (0,)].application(result[node + (1,)])\n",
    "                    if tree[node].label() == 'VP' and check_quantificational_children(result, node):\n",
    "                        return None\n",
    "            else:\n",
    "                if prev_was_leave:\n",
    "                    if leaf in existentials:\n",
    "                        applier = 'existential'\n",
    "                    elif leaf in universal:\n",
    "                        applier = 'universal'\n",
    "                    else:\n",
    "                        applier = tree[node].label()\n",
    "                    result[node] = formalizations[applier](leaf)\n",
    "                    root_cause = result[node]\n",
    "                    prev_was_leave = False\n",
    "                else:\n",
    "                    result[node] = root_cause\n",
    "        else:\n",
    "            prev_was_leave = True\n",
    "            leaf = tree[node]\n",
    "    return result\n",
    "sentence = sentences[1]\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)                                  \n",
    "tokens = sentence.lower().split()\n",
    "parse_tree = list(parser.parse(tokens))[0]\n",
    "parse_tree.pretty_print()\n",
    "res = translate_to_logic(parse_tree)\n",
    "res[()].formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(r.type, r.formula, k) for k, r in res.items() if r is not None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
